---
title: Optimizing bpf map update in xDS mode
authors:
- "@nlgwcy"
reviewers:
- "@robot"
- "@hzxuzhonghu"
- "@supercharge-xsy"
- "@bitcoffeeiux"
approvers:
- "@robot"
- TBD

creation-date: 2024-05-13

---

## Optimizing bpf map update in xDS mode

### Summary

Kmesh is a grid-based data plane governance forwarding system implemented with eBPF. After xDS configurations are distributed to Kmesh-daemon, they are deserialized using a library and then updated as eBPF maps in the kernel. However, the update performance is poor. This proposal introduces optimization strategies to address this issue.

### Motivation

During xDS configuration updates, the performance of eBPF map refresh is poor, resulting in delayed responsiveness to xDS changes notified by Istiod. For example, the time taken for a single routeconfig update is in the order of seconds. Performance analysis profiling revealed that the add and delete operations on the outter_map table (ARRAY_OF_MAPS) are relatively slow, with measured time cost of approximately 5ms for each record addition or deletion. The main reason for this is the [synchronous operations](https://github.com/torvalds/linux/commit/1ae80cf31938c8f77c37a29bbe29e7f1cd492be8) involved in the add and delete processes of this type of map.

[Unit testing](https://github.com/kmesh-net/kmesh/blob/1ae49ce4b623bc888ad2386d9acbc531d6c62d67/pkg/cache/v2/cluster_test.go#L180) eBPF map refresh latency:

```sh
[root@localhost v2]# go test -bench=. --benchtime=100x
goos: linux
goarch: amd64
pkg: kmesh.net/kmesh/pkg/cache/v2
cpu: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
BenchmarkClusterFlush-16             100         835615271 ns/op
BenchmarkFlush-16                    100        1595920212 ns/op
PASS
ok      kmesh.net/kmesh/pkg/cache/v2    245.370s
[root@localhost v2]#
```

#### Goals

The latency of a single xDS configuration update is in the millisecond range.

### Proposal

#### eBPF map update mechanism

In the xDS model, configurations are organized hierarchically. The current design achieves map hierarchy through the map-in-map mechanism of eBPF maps. The specific implementation is as follows:

- xDS model -> proto-c data struct

  ![](pics/kmesh-proto.svg)

- Organized through map-in-map

  ![](pics/kmesh-map-in-map.svg)

  For the value member of map records, if it is a pointer variable involving referencing other data structures, the actual data area is stored in the inner-map:

  - If the value member is a primitive data type (such as int), it can be accessed directly.
  - If the value member is a pointer type, the value stored in the pointer is the index of the inner-map that holds the actual data in the outter_map table (note: the index is updated when writing to the bpf map in the xds-adapter module of kmesh-daemon). When accessing, the inner-map's map fd is first retrieved based on the index, then the actual data is fetched from the inner-map table. For multi-level pointer members, this process is repeated until all pointer information is stripped away.

  The benefits of this design are:

  - xDS model changes do not require redefining eBPF map data structures, providing high flexibility.

#### Optimization solution

The current implementation scheme is as follows:

- Bitmap is used to manage which inner_map records are free, and the bitmap information is stored in the first record of the outter_map.
- During xDS configuration creation, the outter_map is searched for a `idle`idx, and the corresponding inner_map is created. The inner_map information is added to the outter_map table, and the bitmap information is updated as `used`(the outter_map table is also updated).
- During xDS configuration deletion, the idx recorded in the outter_map is searched for, and the corresponding inner_map table is deleted. The record in the outter_map is also removed, and the bitmap information is updated as `idle`.

As we can see, one xDS change involves multiple outter_map refreshes. Here is the optimization approach (space-time trade-off):

- When kmesh-daemon starts, create all outter_map records (including inner_map) at once, using multiple threads to parallelize the refresh process since the outter_map table updates slowly.
- Maintain an `inner_map_mng` table in memory, which keeps track of the idle status of each idx and its corresponding inner_map.
- During xDS configuration creation, for pointer/string members, retrieve an `idle` idx record from inner_map_mng and update the actual content into the inner_map table associated with that idx. Also, update the status of that record as `used`.
- During xDS configuration deletion, find the record corresponding to the idx in `inner_map_mng` and update its status as `idle`.

![](pics/kmesh-map-in-map-optimization.svg)

#### Risks and Mitigations

This approach utilizes a space-time trade-off. When the size of the outter_map table is set to be relatively large, it is not suitable to create all inner_map records at once, as it may lead to a longer startup time for kmesh-daemon and excessive memory consumption. Here are some potential optimization strategies:

- During kmesh-daemon initialization, only create outter_map records of a specific size and then start a background thread to gradually create the remaining records.
- Create outter_map records on demand based on actual usage scenarios.

#### Test

Performance test results of the optimization strategyï¼š

```sh
[root@localhost v2]# go test -bench=. --benchtime=100x
goos: linux
goarch: amd64
pkg: kmesh.net/kmesh/pkg/cache/v2
cpu: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
BenchmarkClusterFlush-16             100            600145 ns/op
BenchmarkFlush-16                    100            283194 ns/op
PASS
ok      kmesh.net/kmesh/pkg/cache/v2    4.047s
```
